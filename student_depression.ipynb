{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Installing necessary packages**"
      ],
      "metadata": {
        "id": "oW90bz1muDy6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "0OBvC_ZfHSQ0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import warnings\n",
        "from functools import partial\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score, precision_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Wrangling (Preprocessing)**"
      ],
      "metadata": {
        "id": "XhhipKi8xEnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataPreprocessor:\n",
        "    def __init__(self, file_path):\n",
        "        self.file_path = file_path\n",
        "        self.data = None\n",
        "        self.encoder = None\n",
        "    def load_data(self):\n",
        "        self.data = pd.read_csv(self.file_path)\n",
        "        print(\"Data loaded successfully.\")\n",
        "    def preprocess_data(self):\n",
        "        if self.data is None:\n",
        "            raise ValueError(\"Data not loaded. Please call `load_data()` first.\")\n",
        "\n",
        " # Data Wrangling (Preprocessing)\n",
        "        self.data = self.data.drop(['id'], axis=1)\n",
        "        self.data['Gender'] = self.data['Gender'].map({'Male': 0, 'Female': 1})\n",
        "\n",
        "        city_counts = self.data['City'].value_counts()\n",
        "        self.data = self.data[self.data['City'].isin(city_counts[city_counts >= 400].index)]\n",
        "\n",
        "        self.data = self.data[self.data['Profession'] == 'Student'].drop(['Profession'], axis=1)\n",
        "\n",
        "        self.data = self.data.drop(['Work Pressure'], axis=1)\n",
        "        self.data = self.data[self.data['Age'] <= 30]\n",
        "        self.data = self.data[self.data['Academic Pressure'] > 0]\n",
        "        self.data = self.data[self.data['Study Satisfaction'] > 0]\n",
        "        self.data = self.data.drop(['Job Satisfaction'], axis=1)\n",
        "\n",
        "        sleep_map = {'Less than 5 hours': 0, '5-6 hours': 1, '7-8 hours': 2, 'More than 8 hours': 3}\n",
        "        self.data = self.data[self.data['Sleep Duration'] != 'Others']\n",
        "        self.data['Sleep Duration'] = self.data['Sleep Duration'].map(sleep_map)\n",
        "\n",
        "        diet_map = {'Healthy': 0, 'Unhealthy': 1, 'Moderate': 2}\n",
        "        self.data = self.data[self.data['Dietary Habits'] != 'Others']\n",
        "        self.data['Dietary Habits'] = self.data['Dietary Habits'].map(diet_map)\n",
        "\n",
        "        degree_mapping = {\n",
        "            r'BSc|BCA|B.Ed|BHM|B.Pharm|B.Com|BE|BA|B.Arch|B.Tech|BBA|LLB': 'Graduated',\n",
        "            r'MSc|MCA|M.Ed|M.Pharm|M.Com|ME|MA|M.Arch|M.Tech|MBA|LLM': 'Post Graduated',\n",
        "            'Class 12': 'Higher Secondary'\n",
        "        }\n",
        "        for pattern, category in degree_mapping.items():\n",
        "            self.data.loc[self.data['Degree'].str.contains(pattern, regex=True, na=False), 'New_Degree'] = category\n",
        "\n",
        "        self.data = self.data[self.data['Degree'] != 'Others']\n",
        "        new_degree_map = {'Graduated': 0, 'Post Graduated': 1, 'Higher Secondary': 2}\n",
        "        self.data['New_Degree'] = self.data['New_Degree'].map(new_degree_map)\n",
        "\n",
        "        self.data['Have you ever had suicidal thoughts ?'] = self.data['Have you ever had suicidal thoughts ?'].map({'Yes': 1, 'No': 0})\n",
        "        self.data['Family History of Mental Illness'] = self.data['Family History of Mental Illness'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "        self.data = self.data.dropna()\n",
        "\n",
        "        self.encoder = OneHotEncoder(sparse_output=False)\n",
        "        encoded_cities = self.encoder.fit_transform(self.data[['City']])\n",
        "        city_encoded_df = pd.DataFrame(encoded_cities, columns=self.encoder.get_feature_names_out(['City']), index=self.data.index)\n",
        "        self.data = pd.concat([self.data, city_encoded_df], axis=1).drop(['City', 'Degree'], axis=1)\n",
        "\n",
        "        print(\"Preprocessing complete.\")\n",
        "\n",
        "    def save_data(self, output_path):\n",
        "        \"\"\"Save the preprocessed dataset to a CSV file.\"\"\"\n",
        "        if self.data is None:\n",
        "            raise ValueError(\"No data to save. Please preprocess the data first.\")\n",
        "\n",
        "        self.data.to_csv(output_path, index=False)\n",
        "        print(f\"Data saved to {output_path}.\")\n"
      ],
      "metadata": {
        "id": "canR9Ai8JG6h"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**pre-process the dataset**"
      ],
      "metadata": {
        "id": "6j5AszE8xat3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = DataPreprocessor(file_path='/content/Student Depression Dataset.csv')\n",
        "preprocessor.load_data()\n",
        "preprocessor.preprocess_data()\n",
        "preprocessor.save_data(output_path=f'{os.getcwd()}/Processed_StudentDepression.csv')"
      ],
      "metadata": {
        "id": "STDIZKEINYiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the cleaned data**"
      ],
      "metadata": {
        "id": "VgA6ZsWlxlkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(f'{os.getcwd()}/Processed_StudentDepression.csv')\n",
        "FIG_PATH = \"./graphics/\"\n",
        "\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(FIG_PATH):\n",
        "    # Create the directory\n",
        "    os.makedirs(FIG_PATH)\n",
        "    print(f\"Directory {FIG_PATH} created.\")\n",
        "else:\n",
        "    print(f\"Directory {FIG_PATH} already exists.\")"
      ],
      "metadata": {
        "id": "nQQOH8gMPCBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform exploratory data analysis (EDA) using correlation matrice and heatmap**"
      ],
      "metadata": {
        "id": "8ATo6R-mxveb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_data = df[['Gender', 'Age', 'Academic Pressure', 'CGPA',\n",
        "       'Study Satisfaction', 'Sleep Duration', 'Dietary Habits',\n",
        "       'Have you ever had suicidal thoughts ?', 'Work/Study Hours',\n",
        "       'Financial Stress', 'Family History of Mental Illness', 'Depression',\n",
        "       'New_Degree']]\n",
        "main_data.head(3)\n",
        "\n",
        "plt.figure(figsize=(20, 10))\n",
        "\n",
        "# Plot the heatmap with increased annotation font size\n",
        "sns.heatmap(\n",
        "    main_data.corr(),\n",
        "    annot=True,\n",
        "    cmap='coolwarm',\n",
        "    annot_kws={\"size\": 12}  # Adjust the annotation font size\n",
        ")\n",
        "\n",
        "# Increase the size of the x and y-axis labels\n",
        "plt.xticks(fontsize=14, rotation=45)  # Adjust fontsize and rotate labels\n",
        "plt.yticks(fontsize=14)\n",
        "\n",
        "# Save the plot to a file (e.g., as a PNG image)\n",
        "plt.savefig(f'{FIG_PATH}mental_health_heatmap.png', bbox_inches='tight', dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ON3C1N63PLN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Model training***\n",
        "\n",
        "Split the data into train/test (80/20), standardize and test-run one classifier."
      ],
      "metadata": {
        "id": "Nn3WyJiyyAf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## SPLITTING THE DATA INTO FEATURES AND TARGET\n",
        "X = df.drop('Depression', axis=1).values  # Features\n",
        "y = df['Depression'].values  # Target\n",
        "\n",
        "## SPLITTING THE DATA INTO TRAIN AND TEST\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "## NORMALIZING THE DATA FEATURES USING STANDARD SCALER\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "## TRAINING THE MODEL USING LOGISTIC REGRESSION\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "## SCORE\n",
        "score = model.score(X_test_scaled, y_test)\n",
        "print(f\"Accuracy: {score*100:.2f}%\")"
      ],
      "metadata": {
        "id": "5U9Twz-mPalI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot confusion matrix for the single trained classifier**"
      ],
      "metadata": {
        "id": "DSo05boMynDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## PLLOTING THE CONFUSION MATRIX\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted: 0', 'Predicted: 1'], yticklabels=['Real: 0', 'Real: 1'])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Values')\n",
        "plt.ylabel('Real Values')\n",
        "# Save the plot to a file (e.g., as a PNG image)\n",
        "plt.savefig(f'{FIG_PATH}mental_health_confusion_matrix.png', bbox_inches='tight', dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0-7gXFeFPii8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perform grid search over the parameter spaces for each model**"
      ],
      "metadata": {
        "id": "sS3r3oHqyybv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "   \"LightGBM\": lgb.LGBMClassifier(random_state=42, verbose=-1),\n",
        "     \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "}\n",
        "\n",
        "# Define the parameter grids for each model\n",
        "param_grids = {\n",
        "    \"Logistic Regression\": {\n",
        "        \"C\": [0.01, 0.1, 1, 10],\n",
        "        \"solver\": [\"liblinear\", \"saga\"],\n",
        "        \"max_iter\": [100, 200, 300]\n",
        "    },\n",
        "        \"Gradient Boosting\": {\n",
        "        \"n_estimators\": [50, 100, 200],\n",
        "        \"learning_rate\": [0.01, 0.1, 0.5],\n",
        "        \"max_depth\": [3, 5, 10]\n",
        "    },\n",
        "    \"Random Forest\": {\n",
        "        \"n_estimators\": [50, 100, 200],\n",
        "        \"max_depth\": [3, 5, 10, None],\n",
        "        \"min_samples_split\": [2, 5, 10],\n",
        "        \"min_samples_leaf\": [1, 2, 4]\n",
        "    },\n",
        "    \"K-Nearest Neighbors\": {\n",
        "        \"n_neighbors\": [3, 5, 10],\n",
        "        \"weights\": [\"uniform\", \"distance\"],\n",
        "        \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\"]\n",
        "    },\n",
        "    \"LightGBM\": {\n",
        "        \"n_estimators\": [50, 100, 200],\n",
        "        \"learning_rate\": [0.01, 0.1, 0.5],\n",
        "        \"max_depth\": [3, 5, 10]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Initialize a dictionary to store the best model and its accuracy\n",
        "best_model_results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Running GridSearchCV for {name}...\")\n",
        "\n",
        "    # Create a GridSearchCV object for each model and its respective parameter grid\n",
        "    grid_search = GridSearchCV(model, param_grids[name], cv=2, n_jobs=-1, scoring=\"accuracy\")\n",
        "\n",
        "    # Fit the grid search (ignoring warnings)\n",
        "    with warnings.catch_warnings():\n",
        "        warnings.simplefilter(\"ignore\")\n",
        "        grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Get the best model and its accuracy\n",
        "    best_model = grid_search.best_estimator_\n",
        "    best_accuracy = grid_search.best_score_\n",
        "\n",
        "    # Store the best model's accuracy and parameters\n",
        "    best_model_results[name] = {\n",
        "        \"accuracy\": best_accuracy,\n",
        "        \"best_params\": grid_search.best_params_\n",
        "    }\n",
        "\n",
        "# Sort the models by accuracy\n",
        "best_model_results_sorted = dict(sorted(best_model_results.items(), key=lambda item: item[1]['accuracy'], reverse=True))\n",
        "\n",
        "# Print sorted results\n",
        "print(best_model_results_sorted)\n"
      ],
      "metadata": {
        "id": "x2cI7sIVR6-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the results\n",
        "plt.figure(figsize=(15, 6))\n",
        "# sns.barplot(x=[result[\"accuracy\"] for result in best_model_results_sorted.values()],\n",
        "#             y=best_model_results_sorted.keys(),\n",
        "#             palette='Blues')\n",
        "\n",
        "sns.barplot(\n",
        "    x=[result[\"accuracy\"] for result in best_model_results_sorted.values()],\n",
        "    y=list(best_model_results_sorted.keys()),\n",
        "    palette='Blues'\n",
        ")\n",
        "\n",
        "plt.xlabel('Accuracy', fontsize=14)\n",
        "plt.title('Grid Search Model Comparison',fontsize=18)\n",
        "\n",
        "# Increase the tick label font sizes, including model names\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)  # Adjust font size of the model names\n",
        "\n",
        "\n",
        "# Add accuracy labels\n",
        "for i, (name, result) in enumerate(best_model_results_sorted.items()):\n",
        "    plt.text(result[\"accuracy\"], i, f'{result[\"accuracy\"]*100:.2f}%', color='black', va='center', fontsize=10)\n",
        "\n",
        "# Save the plot to a file\n",
        "plt.savefig(f'{FIG_PATH}mental_health_model_comparison_grid_search.png', bbox_inches='tight', dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ECa29C9qko89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next we perform XAI on the top-performing model's**\n",
        "\n",
        "LightGBM"
      ],
      "metadata": {
        "id": "NWntlYdDz3gk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "\n",
        "# Suppress specific deprecation warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*force_all_finite.*\")\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*ensure_all_finite.*\")\n",
        "\n",
        "# List of models used\n",
        "model_names_str = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'Gradient Boosting',\n",
        "                   'SVM', 'K-Nearest Neighbors', 'Naive Bayes', 'XGBoost', 'LightGBM']\n",
        "print(model_names_str)\n",
        "\n",
        "# Initialize the LightGBM model with the best parameters if available\n",
        "model_name = \"LightGBM\"\n",
        "best_params = best_model_results.get(model_name, {}).get(\"best_params\", None)\n",
        "\n",
        "# Get feature names (ensure 'Depression' is the target column)\n",
        "feature_names = df.drop('Depression', axis=1).columns\n",
        "\n",
        "# Initialize the LightGBM model with best params if available\n",
        "if best_params:\n",
        "    lgbm_model = lgb.LGBMClassifier(random_state=42, **best_params)\n",
        "else:\n",
        "    # Set default params if best_params is None\n",
        "    lgbm_model = lgb.LGBMClassifier(random_state=42, learning_rate=0.1, max_depth=3, n_estimators=200)\n",
        "\n",
        "# Train the model\n",
        "lgbm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = lgbm_model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"LightGBM Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "# Visualize the feature importance\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Get feature importances\n",
        "importance = lgbm_model.feature_importances_\n",
        "\n",
        "# Sort features by importance\n",
        "indices = np.argsort(importance)[::-1]\n",
        "\n",
        "# Select top 10 features\n",
        "top_features = indices[:10]\n",
        "\n",
        "# Create a horizontal bar plot\n",
        "plt.barh(range(len(top_features)), importance[top_features], color='skyblue')\n",
        "\n",
        "# Set y-axis labels to actual feature names\n",
        "plt.yticks(range(len(top_features)), [feature_names[i] for i in top_features])\n",
        "\n",
        "plt.title(\"LightGBM Feature Importance\", fontsize=18)\n",
        "plt.xlabel(\"Importance\", fontsize=14)\n",
        "plt.ylabel(\"Features\", fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.grid()\n",
        "\n",
        "# Save the plot as a PNG image\n",
        "plt.savefig(f'{FIG_PATH}LightGBM_feature_importance_horizontal.png', bbox_inches='tight', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Optional: Print out the top 10 features and their importance scores\n",
        "for f in range(len(top_features)):\n",
        "    print(\"%d. %s: %f\" % (f + 1, feature_names[top_features[f]], importance[top_features[f]]))\n"
      ],
      "metadata": {
        "id": "wQIlDfD1lDo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Boosting"
      ],
      "metadata": {
        "id": "FghZJIf2-HjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model names and best parameters\n",
        "model_names_str = list(models.keys())\n",
        "print(model_names_str)\n",
        "\n",
        "model_name = \"Gradient Boosting\"\n",
        "\n",
        "# Get the best parameters for the Gradient Boosting model\n",
        "best_params = best_model_results.get(model_name, {}).get(\"best_params\", {})\n",
        "\n",
        "# Get feature names\n",
        "feature_names = df.drop('Depression', axis=1).columns\n",
        "\n",
        "# Initialize the Gradient Boosting model with best parameters\n",
        "gb_model = GradientBoostingClassifier(random_state=42, **best_params)\n",
        "\n",
        "# Train the model\n",
        "gb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = gb_model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Gradient Boosting Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "# Visualize the feature importance\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Get feature importances\n",
        "importance = gb_model.feature_importances_\n",
        "\n",
        "# Sort features by importance\n",
        "indices = np.argsort(importance)[::-1]\n",
        "\n",
        "# Select top 10 features\n",
        "top_features = indices[:10]\n",
        "\n",
        "# Create a horizontal bar plot\n",
        "plt.barh(range(len(top_features)), importance[top_features], color='lightgreen')\n",
        "\n",
        "# Set y-axis labels to actual feature names\n",
        "plt.yticks(range(len(top_features)), [feature_names[i] for i in top_features])\n",
        "\n",
        "plt.title(\"Gradient Boosting Feature Importance\", fontsize=18)\n",
        "plt.xlabel(\"Importance\", fontsize=14)\n",
        "plt.ylabel(\"Features\", fontsize=14)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.grid()\n",
        "\n",
        "# Save the plot as a PNG image\n",
        "plt.savefig('gradient_boosting_feature_importance_horizontal.png', bbox_inches='tight', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Optional: Print out the top 10 features and their importance scores\n",
        "for f in range(len(top_features)):\n",
        "    print(f\"{f + 1}. {feature_names[top_features[f]]}: {importance[top_features[f]]:.6f}\")\n"
      ],
      "metadata": {
        "id": "n7kD-YG81AfO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}